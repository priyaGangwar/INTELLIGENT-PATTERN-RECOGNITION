{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ylEStXuquTVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e2ece7-64a6-432a-d2da-eb14682d5d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "df = pd.read_csv('https://files.grouplens.org/datasets/movielens/ml-100k/u.data', sep='\\t', names=column_names)\n",
        "df = df.drop('timestamp', axis=1)\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "jS7PCY6uA2a_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Add this line to import the os library\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def collaborative_filtering(train_data, test_data, output_dir):\n",
        "    # Create user-item matrix\n",
        "    user_item_matrix = train_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
        "    user_similarity = cosine_similarity(user_item_matrix)\n",
        "    np.fill_diagonal(user_similarity, 0)\n",
        "\n",
        "    user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
        "\n",
        "    # Predict ratings\n",
        "    predictions = []\n",
        "    for _, row in test_data.iterrows():\n",
        "        user, item = row['user_id'], row['item_id']\n",
        "        if item in user_item_matrix.columns:\n",
        "            sim_scores = user_similarity_df.loc[user]\n",
        "            item_ratings = user_item_matrix[item]\n",
        "            weighted_sum = sum(sim_scores * item_ratings) / sum(sim_scores[item_ratings > 0])\n",
        "            predictions.append((user, item, weighted_sum))\n",
        "\n",
        "    # Save to CSV in Google Drive\n",
        "    pd.DataFrame(predictions, columns=['user_id', 'item_id', 'predicted_rating']).to_csv(\n",
        "        output_dir + 'collaborative_filtering_predictions.csv', index=False\n",
        "    )\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/submission/'\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesnâ€™t exist\n",
        "collaborative_filtering(train_df, test_df, output_dir)\n"
      ],
      "metadata": {
        "id": "da_yKACjA43K"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}